# PreTrained-Text-Classification
The goal of this project is to fine-tune a pretrained transformer model (e.g., BERT, RoBERTa, DistilBERT) on a text classification task such as sentiment analysis, topic classification, or spam detection.
