# **Sequence Classification with Hugging Face Transformers**

A full end-to-end project for building, training, evaluating, and deploying a state-of-the-art text classification model using the ğŸ¤— Transformers and ğŸ¤— Datasets libraries.

This project expands the official Hugging Face tutorial:
ğŸ”— [Sequence Classication Guide](https://huggingface.co/docs/transformers/tasks/sequence_classification)
and organizes it into a complete, production-ready workflow.

---

# **ğŸ“Œ Project Overview**

The goal of this project is to fine-tune a pretrained transformer model (e.g., BERT, RoBERTa, DistilBERT) on a text classification task such as sentiment analysis, topic classification, or spam detection.

This repository includes:

* Dataset loading and preprocessing
* Tokenization and input preparation
* Model fine-tuning with Trainer
* Metrics + error analysis
* Batch inference and deployment scripts
* Model saving, versioning, and Hub integration
* Experiment tracking
* Optional: ONNX export and optimization

---

# **ğŸ“ Repository Structure**

```
project-root/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_dataset_exploration.ipynb
â”‚   â”œâ”€â”€ 02_tokenization.ipynb
â”‚   â”œâ”€â”€ 03_finetune_model.ipynb
â”‚   â””â”€â”€ 04_evaluation_and_error_analysis.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py             # training entrypoint
â”‚   â”œâ”€â”€ evaluate.py          # evaluation entrypoint
â”‚   â”œâ”€â”€ predict.py           # batch + single-text predictions
â”‚   â””â”€â”€ export_onnx.py       # optional ONNX conversion
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # untouched dataset
â”‚   â”œâ”€â”€ processed/           # tokenized/imputed data
â”‚   â””â”€â”€ splits/              # reproducible train/val/test
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/         # intermediate checkpoints
â”‚   â”œâ”€â”€ final/               # best model for production
â”‚   â””â”€â”€ hub/                 # ready-to-push Hugging Face repo
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.json
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â””â”€â”€ predictions.csv
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py           # accuracy, f1, etc.
â”‚   â”œâ”€â”€ plotting.py          # confusion matrix, ROC, etc.
â”‚   â””â”€â”€ preprocessing.py     # dataset transforms
â”‚
â”œâ”€â”€ environment.yml or requirements.txt
â””â”€â”€ README.md
```

---

# **âš™ï¸ Setup**

### **1. Create & activate environment**

With pip:

```bash
python3 -m venv .env
source .env/bin/activate
pip install -r requirements.txt
```

Recommended dependencies:

```
transformers
datasets
evaluate
accelerate
scikit-learn
matplotlib
numpy
pandas
```

On Apple Silicon:

```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

(or the MPS build bundled with normal PyTorch wheels)

---

# **ğŸ§  Training Workflow**

## **1. Load dataset**

Example: IMDB sentiment classification

```python
from datasets import load_dataset
dataset = load_dataset("imdb")
```

## **2. Tokenize**

```python
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

def preprocess(batch):
    return tokenizer(
        batch["text"],
        truncation=True,
        padding="max_length",
        max_length=256
    )
```

## **3. Fine-tune the model**

```bash
python scripts/train.py \
  --model_name bert-base-uncased \
  --dataset_name imdb \
  --output_dir models/checkpoints \
  --epochs 3 \
  --batch_size 16 \
  --learning_rate 3e-5
```

Training includes:

* mixed precision (AMP)
* evaluation at end of each epoch
* optional logging via TensorBoard or Weights & Biases

---

# **ğŸ“Š Evaluation & Analysis**

Run:

```bash
python scripts/evaluate.py \
  --model_dir models/final \
  --dataset_name imdb
```

Produces:

* Accuracy, Precision, Recall, F1
* Confusion matrix (`results/confusion_matrix.png`)
* Classification report
* Misclassified example dump

Error analysis details which examples the model struggles with (sarcasm, negation, domain shifts, etc.).

---

# **ğŸ” Inference**

### **Single text**

```bash
python scripts/predict.py --text "I loved this movie!"
```

### **Batch inference**

```bash
python scripts/predict.py --file path/to/file.csv
```

Outputs a CSV with predicted labels + probabilities.

---

# **â˜ï¸ Pushing to Hugging Face Hub**

1. Login:

```bash
huggingface-cli login
```

2. Push:

```python
trainer.push_to_hub()
```

or manually:

```python
model.push_to_hub("your-username/your-model-name")
tokenizer.push_to_hub("your-username/your-model-name")
```

The final model lives under `models/hub/`.

---

# **ğŸš€ Deployment Options**

### Option A â€” Use Hugging Face Inference API

Instant hosting via:

```
https://huggingface.co/<username>/<model>/api
```

### Option B â€” Local FastAPI inference server

### Option C â€” Export to ONNX and serve with ONNX Runtime

```bash
python scripts/export_onnx.py
```

---

# **ğŸ§ª Experiment Tracking**

You can optionally integrate:

* **TensorBoard**
* **Weights & Biases**
* **MLflow**

Example Trainer config:

```python
TrainingArguments(
    ...,
    report_to="tensorboard",
)
```

---

# **ğŸ” Reproducibility**

This repo uses:

* fixed seeds
* stored environment files (requirements/conda env)
* deterministic train/val/test splits
* versioned checkpoints
* `config.json` for model metadata

---

# **ğŸ™Œ Contributing**

Contributions welcome. Ideas include:

* adding new datasets
* experimenting with different architectures
* adding ONNX Runtime benchmarks
* exploring quantization
* improving evaluation visualizations

---

# **ğŸ“ References**

* Hugging Face Transformers: [https://huggingface.co/docs/transformers](https://huggingface.co/docs/transformers)
* Hugging Face Datasets: [https://huggingface.co/docs/datasets](https://huggingface.co/docs/datasets)
* Evaluation: [https://huggingface.co/docs/evaluate](https://huggingface.co/docs/evaluate)
* Accelerate: [https://huggingface.co/docs/accelerate](https://huggingface.co/docs/accelerate)

---
